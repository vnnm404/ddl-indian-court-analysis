import pandas as pd


CHUNK_SIZE = 100_000


# decision judge with case id
judge_case_df = pd.read_csv('../data/keys/judge_case_merge_key.csv')
judge_case_df.drop(['ddl_filing_judge_id'], axis=1, inplace=True)


# rename column
judge_case_cols = list(judge_case_df.columns)
judge_case_cols[1] = 'ddl_judge_id'
judge_case_df.columns = judge_case_cols


# judges df
judges_df = pd.read_csv('../data/judges_clean.csv')
judges_df = judges_df[['ddl_judge_id', 'female_judge']]


# merge the two dfs
judge_data_df = pd.merge(judge_case_df, judges_df, on='ddl_judge_id', how='inner')


judge_data_df


get_ipython().run_cell_magic("time", "", """# in this cell we bake our data to extract features
cases_df = pd.read_csv('../data/_baked/cases_recorded.csv',
                iterator=True,
                chunksize=CHUNK_SIZE,
                low_memory=False)

chunk = 1
for df in cases_df:
    # PART1: merging to obtain decision judge gender
    df = pd.merge(df, judge_data_df, on='ddl_case_id', how='inner')

    # PART2: working with irrelevant columns
    df.drop(['bailable_ipc', 'dist_code', 'ddl_case_id', 'section',
             'cino', 'ddl_judge_id', 'number_sections_ipc',
             'female_adv_pet', 'female_adv_def', 'female_petitioner',
             'date_first_list', 'date_last_list', 'date_next_list',
             'year'
            ], axis=1, inplace=True)

    # PART3: working with dates
    date_columns = ['date_of_decision', 'date_of_filing']
    # parse date columns as dates
    for date_col in date_columns:
        df[date_col] = pd.to_datetime(df[date_col], infer_datetime_format=True, errors='coerce')
    
    # drop rows whose dates could not be parsed
    df.dropna(subset=date_columns, inplace=True)
    
    # add duration column
    df['duration_days'] = (df['date_of_decision'] -df['date_of_filing']).dt.days
    # drop the date columns
    df.drop(date_columns, axis=1, inplace=True)
    # take valid duration rows
    df = df[df['duration_days'] >= 0]

    # PART4: working with gender columns
    gender_columns = ['female_judge', 'female_defendant']
    # filter out unclear genders
    for gender_col in gender_columns:
        # filter on valid data
        df[gender_col] = df[gender_col].astype(str).transform(lambda gen: gen[0])
        gender_valid_filt = (df[gender_col] == '0') | (df[gender_col] == '1')
        df = df[gender_valid_filt]

        # convert to numeric column
        df[gender_col] = pd.to_numeric(df[gender_col])
    
    # write df_acts_sections to a data file
    df.to_csv('../data/_baked/ml/plead_guilty.csv',
              header=(chunk == 1),
              mode='a',
              index=False)

    print('.', end='')
    chunk += 1

print('Done.')""")


# we now load the dataset
features_df = pd.read_csv('../data/_baked/ml/plead_guilty.csv', low_memory=False) 


features_df['court_no'].value_counts()


features_df['purpose_name'].value_counts()


features_df['type_name'].value_counts()


features_df['act'].value_counts()


features_df.columns


pg_filt = (features_df['disp_name'] == 37) | (features_df['disp_name'] == 38)
features_df[pg_filt]['act'].value_counts()


# we remove every act from '7896.0        71' and below (top)
keep_acts = list(features_df[pg_filt]['act'].value_counts().index[:16])


act_filt = features_df['act'].isin(keep_acts)
features_df2 = features_df[act_filt]


keep_courts = features_df2['court_no'].value_counts().index[:22]


court_filt = features_df2['court_no'].isin(keep_courts)
features_df3 = features_df2[court_filt]


pg_filt3 = (features_df3['disp_name'] == 37) | (features_df3['disp_name'] == 38)
keep_types = features_df3[pg_filt3]['type_name'].value_counts().index[:20]


type_filt = features_df3['type_name'].isin(keep_types)
features_df4 = features_df3[type_filt]


pg_filt4 = (features_df4['disp_name'] == 37) | (features_df4['disp_name'] == 38)
keep_purposes = features_df4['purpose_name'].value_counts().index[:25]


purpose_filt = features_df4['purpose_name'].isin(keep_purposes)
features_df5 = features_df4[purpose_filt]


pg_filt5 = (features_df5['disp_name'] == 37) | (features_df5['disp_name'] == 38)
features_df5[pg_filt5]


keep_positions = features_df5['judge_position'].value_counts().index[:22]


position_filt = features_df5['judge_position'].isin(keep_positions)
features_df6 = features_df5[position_filt]


features_df6


pg_filt6 = (features_df6['disp_name'] == 37) | (features_df6['disp_name'] == 38)
features_df6[pg_filt6]


features_df6.to_csv('../data/_baked/ml/plead_guilty_features.csv', index=False)


y = features_df6['disp_name'].transform(lambda x: 1 if x == 37 or x == 38 else 0)


features_df6['y'] = y


features_df6.drop(['disp_name'], axis=1, inplace=True)


features_df6.to_csv('../data/_baked/ml/plead_guilty_features.csv', index=False)


dataset_df = pd.read_csv('../data/_baked/ml/plead_guilty_features.csv')


from sklearn.preprocessing import OneHotEncoder


categorical_columns = ['state_code', 'court_no', 'judge_position', 'type_name', 'purpose_name', 'act']


OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)


categorical_cols_df = dataset_df[categorical_columns]
numerical_df = dataset_df.drop(categorical_columns, axis=1)


OH_categorical_cols_df = pd.DataFrame(OH_encoder.fit_transform(categorical_cols_df))


OH_categorical_cols_df.index = categorical_cols_df.index


encoded_merged_df = pd.concat([OH_categorical_cols_df, numerical_df], axis=1)


# we normalize values so that all values lie in (-1, 1)
normalized_df = (encoded_merged_df-encoded_merged_df.min())/(encoded_merged_df.max()-encoded_merged_df.min())


normalized_df


pg_filt_final = (normalized_df['y'] == 1)
not_pg_filt_final = (normalized_df['y'] == 0)
y_1_df = normalized_df[pg_filt_final]
y_0_df = normalized_df[not_pg_filt_final]


split_index_1 = int(0.7 * len(y_1_df))
split_index_0 = int(0.7 * len(y_0_df))


X_train = pd.concat([y_0_df[:split_index_0], y_1_df[:split_index_1]])
X_test = pd.concat([y_0_df[split_index_0:], y_1_df[split_index_1:]])


y_train = X_train['y']
y_test = X_test['y']


X_train.drop(['y'], axis=1, inplace=True)
X_test.drop(['y'], axis=1, inplace=True)


X_train = X_train.sample(frac=1)
y_train = y_train.sample(frac=1)
X_test = X_test.sample(frac=1)
y_test = y_test.sample(frac=1)


from sklearn.linear_model import SGDClassifier


sgd_clf = SGDClassifier(random_state=42)


sgd_clf.fit(X_train.values, y_train.values)


from sklearn.model_selection import cross_val_score


cross_val_score(sgd_clf, X_train.values, y_train.values, cv=3, scoring="accuracy")


cross_val_score(sgd_clf, X_test.values, y_test.values, cv=3, scoring="accuracy")


y_train[y_train == 1]


y_train[y_train == 0]


from sklearn.metrics import classification_report


y_test_pred = sgd_clf.predict(X_test.values)


print(classification_report(y_test.values, y_test_pred))


from sklearn.ensemble import RandomForestClassifier


clf = RandomForestClassifier(random_state=0)


clf.fit(X_train.values, y_train.values)


cross_val_score(clf, X_test.values, y_test.values, cv=3, scoring="accuracy")


y_test_pred = clf.predict(X_test.values)


print(classification_report(y_test.values, y_test_pred))


from sklearn.neural_network import MLPClassifier


clf = MLPClassifier(random_state=1)


clf.fit(X_train.values, y_train.values)


cross_val_score(clf, X_test.values, y_test.values, cv=3, scoring="accuracy")


y_test_pred = clf.predict(X_test.values)


print(classification_report(y_test.values, y_test_pred))
